{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all videos from a Youtube channel, and get the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import scrapetube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pprint import pprint\n",
    "\n",
    "s4_yt_url = \"https://www.youtube.com/@S4Events\"\n",
    "realpars_yt_url = \"https://www.youtube.com/@realpars\"\n",
    "ics_village_yt_channel = \"https://www.youtube.com/@ICSVillage\"\n",
    "sans_ics_yt_channel = \"https://www.youtube.com/@SANSICSSecurity\"\n",
    "\n",
    "channel_videos = scrapetube.get_channel(channel_url=realpars_yt_url)\n",
    "videos = []\n",
    "for channel_video in channel_videos:\n",
    "    #pprint(channel_video)\n",
    "    video = {}\n",
    "    video['url'] = 'http://www.youtube.com/watch?v=' + channel_video['videoId']\n",
    "    #print(video['url'])\n",
    "    video['title'] = channel_video['title']['runs'][0]['text']\n",
    "    print(video['title'])\n",
    "    tr_nb = 0\n",
    "    try:\n",
    "        video['transcript'] = ''\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(channel_video['videoId'])\n",
    "        #print('transcript found!')\n",
    "        #print(transcript)\n",
    "        tr_nb += 1\n",
    "        for text in transcript:\n",
    "            video['transcript'] = video['transcript'] + text['text']\n",
    "        #print(video['transcript'])\n",
    "        videos.append(video)\n",
    "    except:\n",
    "        next\n",
    "\n",
    "#print(tr_nb)\n",
    "#pprint(len(videos))\n",
    "\n",
    "# Transform the list into a Dataset \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(videos, columns =['title', 'url', 'transcript'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put that into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://docs.pinecone.io/docs/langchain\n",
    "\n",
    "import tiktoken\n",
    "import pinecone\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "OPENAI_KEY = \"XXXX\"\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    #model=model_name,\n",
    "    openai_api_key=OPENAI_KEY,\n",
    ")\n",
    "print(embed)\n",
    "\n",
    "import pinecone\n",
    "\n",
    "index_name = 'otsecgpt'\n",
    "pinecone.init(\n",
    "    api_key='YYYYYY',\n",
    "    environment='gcp-starter'\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "\n",
    "active_indexes = pinecone.list_indexes()\n",
    "print(active_indexes)\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "# Checking the data\n",
    "df\n",
    "\n",
    "index = pinecone.Index(\"otsecgpt\")\n",
    "\n",
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(videos)):\n",
    "    print(record)\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'url': str(record['url']),\n",
    "        'title': record['title'],\n",
    "    }\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(record['transcript'])\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "\n",
    "index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the audio from my elearning videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from moviepy.editor import *\n",
    "\n",
    "# Folder containing the videos\n",
    "input_folder = 'C:\\\\Users\\\\soull\\\\Downloads\\\\elearning_videos'\n",
    "# Output folder\n",
    "output_folder = 'C:\\\\Users\\\\soull\\\\Downloads\\\\elearning_audio'\n",
    "\n",
    "# List the files\n",
    "for videofile in os.listdir(input_folder):\n",
    "    print(videofile)\n",
    "    video = VideoFileClip(input_folder + '\\\\' + videofile)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(output_folder + '\\\\' + videofile + '.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the transcript through AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "access_key = 'ZZZZZ'\n",
    "secret_key = 'ZZZZZ'\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = s3_resource.Bucket(name='XXX_bucket_XXX')\n",
    "\n",
    "for audiofile in os.listdir(output_folder):\n",
    "    bucket.upload_file('C:\\\\Users\\\\soull\\\\Downloads\\\\elearning_audio\\\\' + audiofile, Key='input/' + audiofile)\n",
    "    print('File ' + audiofile + ' uploaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the transcription job using AWS Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://gist.github.com/viethoangtranduong/28a365e6457f35e206779995f488318a & https://towardsdatascience.com/a-quick-tutorial-to-aws-transcribe-with-python-53bbf6605a55\n",
    "\n",
    "import uuid\n",
    "transcribe = boto3.client('transcribe',\n",
    "aws_access_key_id = access_key,\n",
    "aws_secret_access_key = secret_key,\n",
    "region_name = \"us-east-1\")\n",
    "\n",
    "# Get files from the s3 bucket\n",
    "for objects in bucket.objects.filter(Prefix=\"input/\"):\n",
    "    if (objects.key != 'input/'):\n",
    "        id = str(uuid.uuid1())\n",
    "        print(objects.key)\n",
    "        response = transcribe.start_transcription_job(\n",
    "            TranscriptionJobName=id,\n",
    "            LanguageCode='en-US',\n",
    "            MediaFormat='mp3',\n",
    "            Media={\n",
    "                'MediaFileUri': 's3://XXX_bucket_XXX/' + objects.key},\n",
    "            OutputBucketName='XXX_bucket_XXX',\n",
    "            OutputKey='output/' + str(objects.key).replace('input/', '').replace(' ', '_'),\n",
    "            )\n",
    "        print(str(objects.key).replace('input/', '').replace(' ', '_'))\n",
    "        print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "# Credentials\n",
    "access_key = 'XXXXX'\n",
    "secret_key = 'XXXXX'\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = s3_resource.Bucket(name='XXX_bucket_XXX')\n",
    "\n",
    "for objects in bucket.objects.filter(Prefix=\"output/\"):\n",
    "    if('.mp3'in str(objects.key)):\n",
    "        print(objects.key)\n",
    "        obj = s3_resource.Object('XXX_bucket_XXX', objects.key)\n",
    "        file_content = obj.get()['Body'].read().decode('utf-8')\n",
    "        #pprint(file_content)\n",
    "        transcripts.append(file_content)\n",
    "print(len(transcripts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts\n",
    "test = json.loads(transcripts[0])\n",
    "texte = test['results']['transcripts'][0]['transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://docs.pinecone.io/docs/langchain\n",
    "\n",
    "import tiktoken\n",
    "import pinecone\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "OPENAI_KEY = \"YYYYY\"\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    #model=model_name,\n",
    "    openai_api_key=OPENAI_KEY,\n",
    ")\n",
    "print(embed)\n",
    "\n",
    "import pinecone\n",
    "\n",
    "index_name = 'otsecgpt'\n",
    "pinecone.init(\n",
    "    api_key='YYYY',\n",
    "    environment='gcp-starter'\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "\n",
    "active_indexes = pinecone.list_indexes()\n",
    "print(active_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing my videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "# Checking the data\n",
    "\n",
    "\n",
    "index = pinecone.Index(\"otsecgpt\")\n",
    "\n",
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(transcripts)):\n",
    "    print(record)\n",
    "    test = json.loads(transcripts[i])\n",
    "    texte = test['results']['transcripts'][0]['transcript']\n",
    "    print(texte)\n",
    "    # first get metadata fields for this record\n",
    "\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(texte)\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing via the pinecone client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "# Checking the data\n",
    "df\n",
    "\n",
    "index = pinecone.Index(\"otsecgpt\")\n",
    "\n",
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(videos)):\n",
    "    print(record)\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'url': str(record['url']),\n",
    "        'title': record['title'],\n",
    "    }\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(record['transcript'])\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the content of some Kindle books\n",
    "*DRM need to be removed firtst: https://www.cloudwards.net/remove-drm-from-kindle-books/*\n",
    "\n",
    "I also did a little bit a manual clean up after exporting the books to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the content of the folder\n",
    "import os\n",
    "path = 'C:\\\\Users\\\\soull\\\\Desktop\\\\books'\n",
    "#path = 'C:\\\\Users\\\\soull\\\\Desktop\\\\books\\\\test'\n",
    "books_content  = []\n",
    "for bookfile in os.listdir(path):\n",
    "    book = {}\n",
    "    if(bookfile[-4:] == '.txt'):\n",
    "       book['title'] = bookfile[:-4]\n",
    "       print('Title: ' + book['title'])\n",
    "       with open(path + '\\\\' + bookfile,'r', encoding='utf8') as f:\n",
    "        contents = f.read()\n",
    "        book['text'] = contents\n",
    "        books_content.append(book)\n",
    "print('==> ' + str(len(books_content)) + ' books parsed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process into chunks of text and ingest into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "index = pinecone.Index(\"otsecgpt\")\n",
    "\n",
    "batch_limit = 32\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(books_content[4:]):\n",
    "    print(i)\n",
    "    print(record)\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'title': record['title'],\n",
    "        'type': 'book'\n",
    "    }\n",
    "    print(record['title'])\n",
    "    #print(record['text'])\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(record['text'])\n",
    "    print('Nb de chunks ' + str(len(record_texts)))\n",
    "    #print(record_texts)\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    #print(record_metadatas)\n",
    "    #print(len(record_metadatas[0]))\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        print(\"Too long; we're in the loop\")\n",
    "        for k in tqdm(range(0, len(texts), batch_limit)):\n",
    "            #print(str(k)+ ' -> ' + str(k+batch_limit-1)) \n",
    "            ids = [str(uuid4()) for _ in range(batch_limit)]\n",
    "            #print(texts[k])\n",
    "            #print(record_metadatas[k])\n",
    "            try:\n",
    "                embeds = embed.embed_documents(texts[k:k+batch_limit-1])\n",
    "                batch_metadatas = record_metadatas[k:k+batch_limit-1]\n",
    "                index.upsert(vectors=zip(ids, embeds, batch_metadatas))\n",
    "            except:\n",
    "                print('error, trying once again')\n",
    "                embeds = embed.embed_documents(texts[k:k+batch_limit-1])\n",
    "                batch_metadatas = record_metadatas[k:k+batch_limit-1]\n",
    "                index.upsert(vectors=zip(ids, embeds, batch_metadatas))\n",
    "            time.sleep(10)\n",
    "        #print(texts)\n",
    "        #print(\"IDs generated\")\n",
    "        #embeds = embed.embed_documents(texts[k])\n",
    "        #\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to test: ask some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "OPENAI_KEY = \"XXXXX\"\n",
    "openai = OpenAI(\n",
    "   openai_api_key= OPENAI_KEY,\n",
    "   model_name=\"text-davinci-003\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "question_template = \"\"\"\n",
    "You are an expert in Industrial Control Systems cybersecurity.\n",
    "The answer should be in your own words and should not exceed 300 words. The answer should be in English.\n",
    "{context}\n",
    "now based on above context answer the following question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "proper_prompt_template = PromptTemplate(\n",
    "   input_variables=[\"context\",\"question\"],\n",
    "   template=question_template\n",
    ")\n",
    "\n",
    "llm = OpenAI(openai_api_key = OPENAI_KEY,\n",
    "             model_name=\"text-davinci-003\")\n",
    "\n",
    "question = \"How should I configure nmap to perform scan on an industrial control systems environment?\"\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "text_field = \"text\"\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index('otsechotline')\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "context = vectorstore.similarity_search(\n",
    "    question,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "print(context)\n",
    "better_prompt = proper_prompt_template.format(context=context,question=question)\n",
    "standard_prompt = llm(question)\n",
    "print(\"Standard prompt:\\n\",standard_prompt,\"\\n\")\n",
    "print(\"Proper prompt:\\n\",openai(better_prompt),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching to GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import pprint\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "index = pinecone.Index('otsechotline')\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "context = vectorstore.similarity_search(\n",
    "    question,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "OPENAI_KEY = \"XXXXX\"\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=OPENAI_KEY)\n",
    "\n",
    "question = \"What is a VFD?\"\n",
    "\n",
    "text_field = \"text\"\n",
    "# switch back to normal index for langchain\n",
    "\n",
    "context = vectorstore.similarity_search(\n",
    "    question,  # our search query\n",
    "    k=3  # return 2 most relevant docs\n",
    ")\n",
    "print(context[0])\n",
    "print(context[1])\n",
    "print(context[2])\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that explains cybersecurity. All your answers must suggest the most secure way to do things. All the questions you receive are in the context of Industrial Control Systems.\"\n",
    "    ),\n",
    "    SystemMessage(\n",
    "        content=\"You can answer based on the following trusted information : \" + str(context)\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=question\n",
    "    ),\n",
    "]\n",
    "pprint.pprint(chat(messages))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
